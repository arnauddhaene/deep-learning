{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import utils as prologue\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = lambda x: torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigma(x):\n",
    "    e = torch.exp(-2 * x)\n",
    "    return (4 * e) * torch.pow((1 + e), -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda v, t: torch.sum(torch.pow(t - v, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloss = lambda v, t: torch.sum(2 * (v - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Forward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(w1, b1, w2, b2, x): \n",
    "    \n",
    "    x0 = x\n",
    "    \n",
    "    s1 = x0 @ w1 + b1\n",
    "    \n",
    "    x1 = sigma(s1) \n",
    "    \n",
    "    s2 = x1 @ w2 + b2\n",
    "    \n",
    "    x2 = sigma(s2)\n",
    "    \n",
    "    return (x0, s1, x1, s2, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(\n",
    "    w1, b1, w2, b2,\n",
    "    t,\n",
    "    x0, s1, x1, s2, x2,\n",
    "    dl_dw1, dl_db1, dl_dw2, dl_db2\n",
    ") :\n",
    "    dl_dx2 = dloss(x2, t)\n",
    "    \n",
    "    dl_db2 = dl_dx2 * dsigma(s2)\n",
    "    dl_dw2 = x1.view(-1, 1) @ dl_db2.view(1, -1) \n",
    "    \n",
    "    dl_dx1 = dl_db2.view(1, -1) @ w2.t()\n",
    "    \n",
    "    dl_db1 = dl_dx1 * dsigma(s1)\n",
    "    dl_dw1 = x0.view(-1, 1) @ dl_db1.view(1, -1)\n",
    "    \n",
    "    return (dl_dw1, dl_db1, dl_dw2, dl_db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = prologue.load_data(one_hot_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 784]),\n",
       " torch.Size([1000, 10]),\n",
       " torch.Size([1000, 784]),\n",
       " torch.Size([1000, 10]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.size(), train_target.size(), test_input.size(), test_target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target, test_target = train_target * 0.9, test_target * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-1 / train_input.size(0)\n",
    "units = 50\n",
    "classes = 10\n",
    "\n",
    "w1 = torch.empty(train_input.size(1), units).normal_(0, epsilon)\n",
    "b1 = torch.empty(units).normal_(0, epsilon)\n",
    "w2 = torch.empty(units, classes).normal_(0, epsilon)\n",
    "b2 = torch.empty(classes).normal_(0, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dw1 = torch.empty(train_input.size(1), units, units)\n",
    "dl_db1 = torch.empty(units)\n",
    "dl_dw2 = torch.empty(units, classes)\n",
    "dl_db2 = torch.empty(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-1 / train_input.size(0)\n",
    "epochs = 1000\n",
    "\n",
    "for k in range(epochs):\n",
    "    \n",
    "    for sample in range(train_input.size(0)):\n",
    "        \n",
    "        x = train_input[sample, :]\n",
    "        \n",
    "        x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, x)\n",
    "\n",
    "        dl_dw1, dl_db1, dl_dw2, dl_db2 = backward_pass(\n",
    "            w1, b1, w2, b2,\n",
    "            train_target[sample, :],\n",
    "            x0, s1, x1, s2, x2,\n",
    "            dl_dw1, dl_db1, dl_dw2, dl_db2\n",
    "        )\n",
    "\n",
    "        w1 -= eta * dl_dw1\n",
    "        b1 -= eta * dl_db1.view(-1)\n",
    "\n",
    "        w2 -= eta * dl_dw2\n",
    "        b2 -= eta * dl_db2\n",
    "\n",
    "    print(f\"Epoch {k} | loss: {loss(x2, t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
